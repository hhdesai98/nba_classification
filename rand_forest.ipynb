{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we may consider fitting a random forest to our model. We will proceed with the same filters as done in our Logistic model (minimum minutes played and games played)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nba_train = pd.read_csv('Data_Scripting_Cleaning/Full_data/Training_Sets/nba_train.csv')\n",
    "nba_test = pd.read_csv('Data_Scripting_Cleaning/Full_data/Test_Sets/nba_test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_minutes = nba_train[(nba_train['all_nba_c_year']==1)].MP.min()\n",
    "min_G = nba_train[(nba_train['all_nba_c_year']==1)].G.min()\n",
    "nba_filt_train = nba_train[(nba_train['MP']>=min_minutes) & (nba_train['G']>=min_G)]\n",
    "nba_filt_test = nba_test[(nba_test['MP']>=min_minutes) & (nba_test['G']>=min_G)]\n",
    "\n",
    "y_train = nba_filt_train['all_nba_c_year']\n",
    "\n",
    "y_test = nba_filt_test['all_nba_c_year']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "#Now we will fit a random forest model to the data. We will fit this data into a pipeline to scale the data and then fit the model.\n",
    "\n",
    "num_features = ['Age','G', 'GS', 'MP', 'FG', 'FGA', 'FG%', '3P', '3PA', '3P%',\n",
    "       '2P', '2PA', '2P%', 'eFG%', 'FT', 'FTA', 'FT%', 'ORB', 'DRB', 'TRB',\n",
    "       'AST', 'STL', 'BLK', 'TOV', 'PF', 'PTS', 'PER', 'TS%', '3PAr', 'FTr',\n",
    "       'ORB%', 'DRB%', 'TRB%', 'AST%', 'STL%', 'BLK%', 'TOV%', 'USG%', 'OWS',\n",
    "       'DWS', 'WS', 'WS/48', 'OBPM', 'DBPM', 'BPM', 'VORP', 'W',\n",
    "       'num_all_nba']\n",
    "cat_features = ['Tm']\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    [(\"select\", \"passthrough\", num_features),\n",
    "     (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\"), cat_features)],\n",
    "     remainder=\"drop\"\n",
    ")\n",
    "\n",
    "preprocessor.fit(nba_filt_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(preprocessor.transform(nba_filt_train), columns = preprocessor.get_feature_names_out())\n",
    "X_test = pd.DataFrame(preprocessor.transform(nba_filt_test), columns = preprocessor.get_feature_names_out())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To fit this model we will consider a grid of hyper-parameters. Since this grid is quite large (7200), we will utilize a randomized search where we consider 500 random subsets of the hyper-parameters."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also consider what these hyper-parameters mean.\n",
    "1) n_estimators: How many decision trees will be created in total\n",
    "2) max_depth: The longest path between the root node and the leaf. This is essentially controlling how many splits are allowed.\n",
    "3) min_samples_lead: Minimum number of samples to required for a leaf node. This determines how specific a leaf can be.\n",
    "4) min_samples_split: Minimum number of samples a node must have for it to be split\n",
    "5) max_features: Maximum number features randomly selected for each tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can fit our Random Forest model to the data.\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "rf = RandomForestClassifier(random_state=0)\n",
    "param_grid = {\n",
    "   'n_estimators': [100, 200, 300, 400, 500],\n",
    "   'max_depth': [5, 10, 15, 20, 25],\n",
    "   'min_samples_split': [2, 5, 10, 15, 20, 25, 30, 40],\n",
    "   'min_samples_leaf': [1, 2, 5, 10, 15, 20],\n",
    "   'max_features': [ 'sqrt', 'log2', 0.2, .4, .8, 1.0]\n",
    "}\n",
    "\n",
    "\n",
    "CV_rfc = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, cv= 5,\n",
    "                            random_state=0, n_iter=1000)\n",
    "CV_rfc.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, CV_rfc.predict(X_test), target_names=['Not All-NBA', 'All-NBA']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(y_test, CV_rfc.predict(X_test), rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coef_df = pd.DataFrame({'coefs':CV_rfc.best_estimator_.feature_importances_,\n",
    "                          'features':X_train.columns})\n",
    "coef_df_nz = coef_df[coef_df['coefs']!=0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "alt.Chart(coef_df_nz).mark_bar().encode(\n",
    "    y='coefs',\n",
    "    x=alt.Y('features', sort='-y'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
